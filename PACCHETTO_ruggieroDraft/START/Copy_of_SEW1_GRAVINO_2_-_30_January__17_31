A Communication and Information Technology tailored on the shape of our minds


In a 2018 interview about the status of the Internet Tim Barners-Lee said: “for many years there was a feeling that the wonderful things on the web were going to dominate and we’d have a world with less conflict, more understanding, more and better science, and good democracy”. Nowadays, instead, “humanity connected by technology on the web is functioning in a dystopian way. We have online abuse, prejudice, bias, polarisation, fake news, there are lots of ways in which it is broken.” Apparently, something is rotten in the state of the Internet. Several voices raised alarms and many authorities are trying to face the issues. For example, the Office of the High Commissioner for the Human Rights of the United Nations, recently released a series of guidelines for various nations, pushing governments to fix the most ugent emergencies about the web. It took a decade for humans to implement the largest infrastructure of their history, and in the same amount of time the utopian visions about about the impact of the internet turned into dystopian ones. How could that happen?
Several studies link the phenomena mentioned by Barners-Lee (polarization, fake news, etc) to the design of our Information and Communication Technologies. In particular, Information Filtering systems and Recommender Systems. If their role in the mentioned phenomena is still under debate, it is not debatable their crucial importance in the experience of the web. In fact, those system are the unavoidable passage for every content we experience through the internet. In social media platform, if something it is not proposed by a Recommender System, it is as if it does not exist at all. With an increasing number of persons switching to social media platforms as main news providers their role is becoming more and more important for the very foundation of our societies.
Literature is divided on the effects of Recommender Systems. The main points of controversy is the impact of those systems on the diversity of contents proposed to the user This diversity influences the vision of reality that people will derive from contents. Lack of diversity, some argue, is causing bias, homophily, polarization, intolerance and the tendency to believe and to spread fake news. 
An aspect often neglected in this controversy is the human nature. In fact, humans, by themselves, for ages showed the propension to group in polarized tribes or to spread fake news about other tribes. But the peculiarity of human cognitive mechanism of information elaboration are usually not take into the account in an aware way. For example, the most popular technique for the implementation of a Recommender System is the so called Collaborative Filtering. It is simply based on the assumption that similar users will like similar contents, that sound very reasonable. The success of this methodology is due to its formal elegance (matrix factorization techniques involved are simple and understandable), its precision in the recommendation of appreciated contents, its ease of implementation and its scalability. The problem is that humans on their own already have the tendency to form polarized formations. If we base our suggestions plainly on human behaviour, we create a reinforcement loop pushing this mechanism to the extreme.
The way in which we process informations, the cognitive biases we all have, need to be taken into the account. We have a natural tendency to homophily, to tribes, to repetition of the old comfortable things we like. If the problem might be in the human nature and in the neglection of it in the design of our information technologies, our very nature also contain the solution. One of our major trait as a specie is the ability to learn. As we are attracted by our past we are also pushed toward novelties by our curiosity. 
There is a growingly urgent need for a novel generation of information and communication technologies tailored on the shape of our mind, taking into the account the actual way we process information. In the specific case of the Recommender Systems, we probably need to base them on a novel framework, where the task is not anymore to propose to the user something she or he likes but a more complex one. If we consider learning as a process of extraction of information, and thus value, from contents, our task should be to optimize the amount of value extracted by humans in their lifetime. Thus when we suggest contents we should on one side take into the account what we could call the semantic distance of that content form the person point of view. This means that it should be too close: it would be completely known and thus boring. It should not be too far either: it could be unintelligible or unpleasant (it has been proven that contents too far from a given point of view could result in a “backfire” effects). On the other side, when we suggest a content we should also take into the account the structure of the space of contents, and how much of that space learning a specific content will make accessible, allowing the user to extract value from other contents. This kind of dynamics of unlocking has been studied in the research about the so called Adjacent Possible. 
Several intellectual tool coming from statistical physics can help in the definition of the new framework for Recommender System. As, also, the wide literature about human cognitive abilities. Several of the strategic pieces are probably there. The issues of the internet are often faced as separate problems by governments and institutions, trying to fixing them with focalised interventions. This effort need to be extended also to an intellectual one in the comprehension of the issue and in the conception of novel theories and tools. In other words, we need to embrace the challenge of redesigning our information system in a way they could be closer to what they were meant to be at the dawn of the Internet age. Before we reach the sunset.