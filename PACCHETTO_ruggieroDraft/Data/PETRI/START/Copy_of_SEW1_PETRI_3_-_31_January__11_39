AI started a new gold rush. It is causing huge changes in industry, academia and in society. Companies rush to hire young deep-learning wizards. Universities restructure their courses to include all types of machine learning. Traditionally boring computer science conferences revamp themselves into dazzling shows of socially disrupting applications and egos. 


It wasn’t always the case. This AI renaissance follows decades of slow development and rides on the wave of the explosion of computing power and availability of large annotated datasets. These finally allowed neural networks to outperform other competing technologies. They now reach human-level performances in tasks, such as driving a car, planning a path through a crowded station and -importantly- recognize fluffy cats in photographs. 


However, AI was about something else originally. It was about understanding the origin of human intelligence. And whether we could we reconstruct it. This question inspired the first models of neural networks. 
ADD BITS ABOUT 1948, turing etc…
They were crudely modeled after the apparently incoherent network of neurons inside our heads and promised to provide a window into what made us able to learn, think, plan, live. 


At long last, we might finally answer some of these questions thanks to AI systems human-like performances. They provide an explicit way to compare how humans and deep networks learn and perform tasks. In many cases, they seem to be doing the very same thing. For example, studies founds that the deep activations of convolutional networks mimic those of the human visual areas. When trained on sensory inputs, deep networks approximate the human sensory cortical processing. 


This similarity goes deeper. Neural networks and the human brain appear to represent space in the same way. Indeed, neural networks trained to perform spatial navigation display units that resemble mammalian place and cell grids in the mammalian hippocampus. A place cell fires when the animal is near a specific position. Populations of place cells thus create an atlas, similar to a patchwork, that covers the space the animal inhabits. Grid cells are even more striking: each one fires when the animal crosses the corners of a hexagonal grid that covers space; jointly they provide the animal with a navigation grid. 


The mathematics that describes 
Deep networks and the brain learn the shape of space to navigate it. 


Other functions (memory, tasks) share similarities with spatial coding. 


Therefore, they are likely to be topologically encoded too. And this is huge.










Notes:
- I dont know whether to keep the second paragraph
- I dont know where to put the billboard paragraph