Topic sentence structure


AI started a new gold rush. It is causing huge changes in industry, academia and in society. Companies rush to hire young deep-learning wizards. Universities restructure their courses to include all types of machine learning. Traditionally boring computer science conferences revamp themselves into dazzling shows of socially disrupting applications and egos. 


It wasn’t always the case. This AI renaissance follows decades of slow development and rides on the wave of the explosion of computing power and availability of large annotated datasets. These finally allowed neural networks to outperform other competing technologies and to reach human-level performances in tasks, such as driving a car, planning a path through a crowded station and -importantly- recognize fluffy cats in photographs. 


However, AI was about something else originally. It was about understanding the origin of human intelligence. And whether we could we reconstruct it. This question inspired the first models of neural networks. ADD BITS ABOUT 1948, turing etc…
They were crudely modeled after the apparently incoherent network of neurons inside our heads and promised to provide a window into what made us able to learn, think, plan, live. 


At long last, we might finally answer some of these questions thanks to AI systems human-like performances. They provide a direct window on the 
For example, the deep activations of convolutional networks mimic those of the human visual areas. Other deep networks, trained on sensory inputs, reproduce the human sensory cortical processing. Even more interestingly, neural networks trained to perform spatial navigate develop activation patterns that are strikingly similar to those observed in mammalian place and cell grids. 


AI models and the brain describe the world in very similar ways.
This is very evident in how space is represented 


This encoding is topological in nature and this is surprising…  because topology is very rarefied and arcane.


Other functions (memory, tasks) share similarities with spatial coding. 


Therefore, they are likely to be topologically encoded too. And this is huge.