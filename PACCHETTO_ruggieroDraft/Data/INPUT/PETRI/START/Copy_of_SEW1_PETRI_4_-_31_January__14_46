AI started a new gold rush. It is causing huge changes in industry, academia and in society. Companies rush to hire young deep-learning wizards. Universities restructure their courses to include all types of machine learning. Traditionally boring computer science conferences revamp themselves into dazzling shows of socially disrupting applications and egos. 


It wasn’t always the case. This AI renaissance follows decades of slow development and rides on the wave of the explosion of computing power and availability of large annotated datasets. These finally allowed neural networks to outperform other competing technologies. They now reach human-level performances in tasks, such as driving a car, planning a path through a crowded station and -importantly- recognize fluffy cats in photographs. 


However, AI was about something else originally. It was about understanding the origin of human intelligence. And whether we could we reconstruct it. This question Alan Turing to theorize the existence of Type B computers,  inspired the first models of neural networks. 
ADD BITS ABOUT 1948, turing etc…
They were crudely modeled after the apparently incoherent network of neurons inside our heads and promised to provide a window into what made us able to learn, think, plan, live.  
ADD KILLBOARD HERE?


At long last, AI systems might shed some light of how the human brain works. In fact, deep networks with human-level performances now provide an explicit way to compare how humans and machines learn and perform tasks. In many cases, they seem to be doing the very same thing. For example, studies founds that the deep activations of convolutional networks mimic those of the human visual areas. When trained on sensory inputs, deep networks approximate the human sensory cortical processing.  MAYBE ADD ONE MORE EXAMPLE?


This similarity between deep networks and brains goes deeper. Neural networks and the human brain appear to represent space in the same way. Indeed, neural networks trained to perform spatial navigation display units that resemble mammalian place and cell grids in the mammalian hippocampus. A place cell fires when the animal is near a specific position. Populations of place cells thus create an atlas, similar to a patchwork, that covers the space the animal inhabits. Grid cells are even more striking: each one fires when the animal crosses the corners of a hexagonal grid that covers space. Jointly they provide the animal with a navigation grid. 


These navigational structures are topological in nature. Topology is an old and quite arcane branch of mathematics. It focuses on the concept of shape. Scholars usually consider it beautiful, and of little practical use. For example, in 1968 a character of the Russian writer E. Solzhenitsyn could be heard exclaiming “Topology! The stratosphere of human thought! In the twenty-fourth century it might possibly be of use to someone...”. It turns that was a very pessimistic prediction. Recent work on stochastic encoding show that the structures learned by grid cells are those that optimize information compression in the environment the animal leaves it (e.g. 2d for mice and crawling bats, 3d for flying bats). The predicted grid structures correspond closely to those predicted by the densest packings of sphere in the corresponding dimension, e.g. the hexagonal grid in two dimension and the cannonball stacking in 3D dimensions. 


The link between optimal packing and highest compression vanishes in higher dimensions. In fact, the correspondence between stochastic encoding and topology of the space is rooted in the fact that in low dimensional spaces the topological structure defines the differential structure. This however is no longer true for dimensions higher than 3. This means that the topology of the space does not determine the geometry of it. It is unclear then how we, and deep learning systems, are able to produce a navigational map to navigate the more complex spaces that lie behind complex cognitive tasks, such as memory spaces or value spaces. 


Final paragraph 1 - Article intro: 
Here we show that the grid structure learned by deep networks navigating in high dimensions correspond/does not correspond to the simplest topological packing.  dfnsofanofan




Final paragraph 2 - commentary/story: 






Notes:
- I dont know whether to keep the second paragraph
- I dont know where to put the billboard paragraph
- paragraphs are not balanced and well-divided anymore…