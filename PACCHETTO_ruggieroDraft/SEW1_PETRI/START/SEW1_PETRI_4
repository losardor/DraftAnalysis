The way we learn to navigate in space reflects how we describe the world


AI started a new gold rush. It is causing huge changes in industry, academia and in society. Companies rush to hire young deep-learning wizards. Universities restructure their courses to include all types of machine learning. Traditionally boring computer science conferences revamp themselves into dazzling shows of socially disrupting applications and egos. It wasn’t always the case. This AI renaissance follows decades of slow development and rides on the wave of the explosion of computing power and availability of large annotated datasets. The combination of these two allowed neural networks to outperform other competing technologies. Deep networks now reach human-level performances in many complex tasks, such as driving a car, planning a path through a crowded station and -importantly- recognize fluffy cats in photographs. 


However, AI was about something else originally. Its motivation was understanding the origin of human intelligence. And whether we could we reconstruct it. These questions inspired Alan Turing in 1948 to theorize the existence of unorganized machines --machines which could gradually learn and eventually resemble human intelligence. These in turn inspired the first models of neural networks. They were crude attempts at modeling the apparently incoherent hairball of neurons inside our head but they already promised to open a window into what made us able to learn, think, plan, live. These initial promises however were by and large broken during the AI winter of the 70s and 80s. 


At long last, AI systems are shining some light of how the human brain works. Recent research  in deep networks showed that it is possible to explicitly compare compare how humans and machines learn and perform tasks. And in many cases, deep networks are more than simple toy models. They appear to be doing the very same thing. As an example, in networks trained to recognize images, deep activations of convolutional networks mimic those of the human visual areas. When trained on sensory inputs instead, deep networks approximate the human sensory cortical processing. 


The similarity between deep networks and brains goes deeper. Neural networks and the human brain appear to represent space in the same way. Recent research showed that neural networks performing spatial navigation develop units resembling the behaviour of the neurons responsible for encoding space. These neurons fall in two categories. The first type, called place cells, fire when the animal is near a specific position in space. Populations of such cells thus create an atlas, similar to a patchwork, that covers the space the animal inhabits, like a set of partially overlapping maps. The second type, grid cells, is even more striking: each one fires when the animal crosses the corners of a hexagonal grid that spans space. Jointly they provide the animal with a navigation grid, place cells providing localization, grid cells contributing to path navigation. 


These shared navigational structures are topological in nature. Topology is a rather arcane branch of mathematics. It descfddfribes the connectivity and the shape of arbitrary spaces. Scholars often consider it beautiful, and of little practical use. For example, in 1968 a character of the Russian writer E. Solzhenitsyn could be heard exclaiming: “Topology! The stratosphere of human thought! In the twenty-fourth century it might possibly be of use to someone...”. It turns that was a pessimistic prediction. Recent research showed that populations of neurons trying to encode space in a parsimonious way develop grid cells. While the shape of the lattice of such grid cells depends on the environment dimension (2D for mice, 3D for flying bats), it always matches that obtained with the densest packing of spheres in the corresponding dimension. Densest packings however are a purely topological concept because they only rely on the connectivity pattern of the spheres, rather than on their size. 


This link between topology and optimal compression vanishes in higher dimensions. In fact, the correspondence between optimal encoding and topology of spaces is rooted in the fact that in low dimensional spaces connectivity defines geometry. Formally, the topological structure defines the differential structure. This however is no longer true for dimensions higher than 3. For most of dimensions larger than 4 there exist multiple differential structures compatible with the same topology. It is unclear then what would then happen to our capacity to explore and navigate such spaces, despite the practical evidence that the same structures involved in spatial navigation are involved in navigation of richer spaces, such as memory or social spaces. 


Here we show that the grid structure learned by deep networks navigating in high dimensions correspond/does not correspond to the simplest topological packing.  While it is hard to study higher dimensional exploration in live animals, this can be done in synthetic networks. We follow here work by Mirowski et al (2018) and train deep neural networks to integrate paths of synthetic mice. We consider mice living in progressively higher dimensions and show how the response patterns of grid-like units change with dimensionality. We characterize their topological structure using recent topological data analysis tools (Ghrist 2008) and relate them to the prediction of optimal compression theory. 
(if it works) Finally, we prove bounds on the entropic of the learned lattice and estimate the dimensionality of memory spaces using data from memory-recollection experiments. 
(it it doesn’t) Finally, we relate the novel grid cell structures detected to the patterns observed in data from memory-recollection experiments.




END 


————
I started out unsure about what type of text I wanted to write. I started as a kind of news and views piece then switched. I am not sure I made my mind yet, to be honest, but anyway I tried to push the text toward the introduction of the paper on which I’ll start working on in the next month on hyperdimensional mice (in the sense above..), hence the lack of results. 
I got the feeling the first paragraph will have to go for the paper.. too much emphasis on something unrelated..